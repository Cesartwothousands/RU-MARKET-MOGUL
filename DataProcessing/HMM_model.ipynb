{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of the data: (191327, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Load processed data\n",
    "data = pd.read_csv('processed_stock_data.csv')\n",
    "\n",
    "# Remove rows with Volume equal to 0\n",
    "data = data[data['Volume'] != 0]\n",
    "\n",
    "# Remove rows containing NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Remove rows containing infinite values\n",
    "numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "for column in numeric_columns:\n",
    "    if np.isinf(data[column]).any():\n",
    "        data = data[~np.isinf(data[column])]\n",
    "\n",
    "# Remove rows where the first three attributes are all 0\n",
    "data = data[~((data['Close-Open/Open'] == 0) & (data['High-Open/Open'] == 0) & (data['Open-Low/Open'] == 0))]\n",
    "\n",
    "# Take absolute values for 'High-Open/Open' and 'Open-Low/Open' columns\n",
    "data['High-Open/Open'] = data['High-Open/Open'].abs()\n",
    "data['Open-Low/Open'] = data['Open-Low/Open'].abs()\n",
    "\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data[['Close-Open/Open', 'High-Open/Open', 'Open-Low/Open', 'Volume']] = scaler.fit_transform(data[['Close-Open/Open', 'High-Open/Open', 'Open-Low/Open', 'Volume']])\n",
    "\n",
    "# Check the final shape of the data\n",
    "print(\"Final shape of the data:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t=time.time()\n",
    "# Group the dataset by Ticker\n",
    "grouped_data = data.groupby('Ticker')\n",
    "\n",
    "# Get the list of unique Tickers after grouping\n",
    "unique_tickers = list(grouped_data.groups.keys())\n",
    "\n",
    "# Calculate the number of Tickers per fold\n",
    "tickers_per_fold = len(unique_tickers) // 5\n",
    "\n",
    "# Split the data into 5 non-overlapping subsets based on Ticker\n",
    "ticker_splits = []\n",
    "start_ticker = 0\n",
    "for i in range(5):\n",
    "    end_ticker = start_ticker + tickers_per_fold\n",
    "    if i == 4:  # To include any remaining Tickers in the last fold\n",
    "        end_ticker = len(grouped_data)\n",
    "    ticker_splits.append(data[data['Ticker'].isin(unique_tickers[start_ticker:end_ticker])])\n",
    "    start_ticker = end_ticker\n",
    "\n",
    "# Prepare a dictionary to store mean squared errors for each hidden state number\n",
    "mse_dict = {}\n",
    "state_range=range(2, 10)\n",
    "iter=1000\n",
    "# Iterate over the possible hidden state numbers\n",
    "for n_states in state_range:\n",
    "    mse_list = []\n",
    "    \n",
    "    # Iterate over the ticker_splits\n",
    "    for i in range(len(ticker_splits)):\n",
    "        # Use one split for validation and the others for training\n",
    "        train_data = pd.concat([ticker_splits[j] for j in range(len(ticker_splits)) if j != i])\n",
    "        val_data = ticker_splits[i]\n",
    "\n",
    "        # Get the feature matrix for training and validation\n",
    "        X_train = train_data[['Close-Open/Open', 'High-Open/Open', 'Open-Low/Open', 'Volume']].values\n",
    "        X_val = val_data[['Close-Open/Open', 'High-Open/Open', 'Open-Low/Open', 'Volume']].values\n",
    "\n",
    "        # Fit the HMM model with the current hidden state number\n",
    "        model = hmm.GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=iter)\n",
    "        model.fit(X_train)\n",
    "\n",
    "        # Predict the hidden states for the validation set\n",
    "        hidden_states_val = model.predict(X_val)\n",
    "\n",
    "        # Calculate the mean squared error for the validation set\n",
    "        mse = mean_squared_error(X_val[:, 0], hidden_states_val)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "    # Calculate the average mean squared error for the current hidden state number\n",
    "    mse_dict[n_states] = np.mean(mse_list)\n",
    "    tt=time.time()\n",
    "    print(tt-t)\n",
    "    t=time.time()\n",
    "    print(f\"Hidden state number: {n_states}, Average MSE: {np.mean(mse_list)}\")\n",
    "    \n",
    "# Find the hidden state number with the lowest average mean squared error\n",
    "optimal_hidden_states = min(mse_dict, key=mse_dict.get)\n",
    "print(f\"Optimal hidden state number: {optimal_hidden_states}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "\n",
    "# Convert the 'Date' column to a datetime object\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort the dataset by the 'Date' column\n",
    "data = data.sort_values(by='Date')\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Prepare the dataset for cross-validation\n",
    "X = data[['Close-Open/Open', 'High-Open/Open', 'Open-Low/Open', 'Volume']].values\n",
    "\n",
    "# Initialize the TimeSeriesSplit splitter with 5 splits\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "mse_dict = {}\n",
    "state_range = range(2, 4)\n",
    "for n_states in state_range:\n",
    "    mse_list = []\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "\n",
    "        model = hmm.GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=1000000000)\n",
    "        model.fit(X_train)\n",
    "\n",
    "        hidden_states_val = model.predict(X_val)\n",
    "\n",
    "        mse = mean_squared_error(X_val[:, 0], hidden_states_val)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "    mse_dict[n_states] = np.mean(mse_list)\n",
    "    tt=time.time()\n",
    "    print(tt-t)\n",
    "    t=time.time()\n",
    "    print(f\"Hidden state number: {n_states}, Average MSE: {np.mean(mse_list)}\")\n",
    "\n",
    "optimal_hidden_states = min(mse_dict, key=mse_dict.get)\n",
    "print(f\"Optimal hidden state number: {optimal_hidden_states}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
